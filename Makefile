# Point Cloud Style Transfer - é¡¹ç›®è‡ªåŠ¨åŒ–è„šæœ¬
# ====================================================

# å˜é‡å®šä¹‰
DOCKER_COMPOSE = docker-compose
PROJECT_NAME = pointcloud-style-transfer
CONTAINER_NAME = pointcloud-style-transfer
JUPYTER_CONTAINER = pc-jupyter
TENSORBOARD_CONTAINER = pc-tensorboard

# æ•°æ®è·¯å¾„
DATA_ROOT = datasets
SIM_DATA_DIR = $(DATA_ROOT)/simulation
REAL_DATA_DIR = $(DATA_ROOT)/real_world
PROCESSED_DATA_DIR = $(DATA_ROOT)/processed_hierarchical

# æ¨¡å‹è·¯å¾„
CHECKPOINT_DIR = checkpoints
LOG_DIR = logs
RESULT_DIR = results

.PHONY: help setup build up down restart logs shell jupyter tensorboard \
        preprocess train test inference visualize clean status \
        install-deps check-gpu monitor

# é»˜è®¤ç›®æ ‡
help:
	@echo "Point Cloud Style Transfer - Docker Commands"
	@echo "============================================="
	@echo ""
	@echo "ğŸ³ Docker ç®¡ç†:"
	@echo "  make build         - æ„å»ºDockeré•œåƒ"
	@echo "  make up            - å¯åŠ¨æ‰€æœ‰æœåŠ¡"
	@echo "  make down          - åœæ­¢æ‰€æœ‰æœåŠ¡"
	@echo "  make restart       - é‡å¯æ‰€æœ‰æœåŠ¡"
	@echo "  make status        - æŸ¥çœ‹æœåŠ¡çŠ¶æ€"
	@echo ""
	@echo "ğŸ“Š æœåŠ¡è®¿é—®:"
	@echo "  make shell         - è¿›å…¥ä¸»å®¹å™¨shell"
	@echo "  make jupyter       - å¯åŠ¨Jupyter Lab"
	@echo "  make tensorboard   - å¯åŠ¨TensorBoard"
	@echo "  make logs          - æŸ¥çœ‹å®æ—¶æ—¥å¿—"
	@echo ""
	@echo "ğŸ”„ æ•°æ®å¤„ç†:"
	@echo "  make preprocess    - æ•°æ®é¢„å¤„ç†"
	@echo "  make setup-dirs    - åˆ›å»ºå¿…éœ€ç›®å½•"
	@echo ""
	@echo "ğŸš€ æ¨¡å‹è®­ç»ƒ:"
	@echo "  make train         - å¼€å§‹è®­ç»ƒ"
	@echo "  make train-resume  - æ¢å¤è®­ç»ƒ"
	@echo "  make monitor       - ç›‘æ§è®­ç»ƒè¿›åº¦"
	@echo ""
	@echo "ğŸ§ª æµ‹è¯•ä¸æ¨ç†:"
	@echo "  make test          - è¿è¡Œæµ‹è¯•"
	@echo "  make inference     - å•æ–‡ä»¶æ¨ç†"
	@echo "  make visualize     - å¯è§†åŒ–ç»“æœ"
	@echo ""
	@echo "ğŸ”§ ç³»ç»Ÿå·¥å…·:"
	@echo "  make check-gpu     - æ£€æŸ¥GPUçŠ¶æ€"
	@echo "  make clean         - æ¸…ç†ä¸´æ—¶æ–‡ä»¶"
	@echo "  make clean-all     - æ·±åº¦æ¸…ç†"

# ==================== Docker ç®¡ç† ====================

# æ„å»ºé•œåƒ
build:
	@echo "ğŸ”¨ æ„å»ºDockeré•œåƒ..."
	$(DOCKER_COMPOSE) build --no-cache

# å¿«é€Ÿæ„å»ºï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
build-fast:
	@echo "âš¡ å¿«é€Ÿæ„å»ºDockeré•œåƒ..."
	$(DOCKER_COMPOSE) build

# å¯åŠ¨æœåŠ¡
up:
	@echo "ğŸš€ å¯åŠ¨æ‰€æœ‰æœåŠ¡..."
	$(DOCKER_COMPOSE) up -d
	@echo "âœ… æœåŠ¡å·²å¯åŠ¨!"
	@echo "ğŸ“Š Jupyter Lab: http://localhost:8888"
	@echo "ğŸ“ˆ TensorBoard: http://localhost:6006"

# åœæ­¢æœåŠ¡
down:
	@echo "ğŸ›‘ åœæ­¢æ‰€æœ‰æœåŠ¡..."
	$(DOCKER_COMPOSE) down

# é‡å¯æœåŠ¡
restart:
	@echo "ğŸ”„ é‡å¯æœåŠ¡..."
	$(DOCKER_COMPOSE) restart

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
status:
	@echo "ğŸ“‹ æœåŠ¡çŠ¶æ€:"
	$(DOCKER_COMPOSE) ps

# ==================== æœåŠ¡è®¿é—® ====================

# è¿›å…¥ä¸»å®¹å™¨
shell:
	@echo "ğŸš è¿›å…¥ä¸»å®¹å™¨..."
	docker exec -it $(CONTAINER_NAME) /bin/bash

# è¿›å…¥å®¹å™¨å¹¶æ¿€æ´»condaç¯å¢ƒï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
shell-root:
	@echo "ğŸ”‘ ä»¥rootèº«ä»½è¿›å…¥å®¹å™¨..."
	docker exec -it --user root $(CONTAINER_NAME) /bin/bash

# å¯åŠ¨Jupyter Lab
jupyter:
	@echo "ğŸ“Š å¯åŠ¨Jupyter Lab..."
	docker exec -d $(CONTAINER_NAME) jupyter lab \
		--ip=0.0.0.0 --port=8888 --no-browser --allow-root \
		--NotebookApp.token='' --NotebookApp.password=''
	@echo "âœ… Jupyter Lab å·²å¯åŠ¨: http://localhost:8888"

# å¯åŠ¨TensorBoard
tensorboard:
	@echo "ğŸ“ˆ å¯åŠ¨TensorBoard..."
	docker exec -d $(CONTAINER_NAME) tensorboard \
		--logdir=$(LOG_DIR) --host=0.0.0.0 --port=6006
	@echo "âœ… TensorBoard å·²å¯åŠ¨: http://localhost:6006"

# æŸ¥çœ‹æ—¥å¿—
logs:
	@echo "ğŸ“œ æŸ¥çœ‹å®æ—¶æ—¥å¿—..."
	$(DOCKER_COMPOSE) logs -f

# æŸ¥çœ‹ç‰¹å®šæœåŠ¡æ—¥å¿—
logs-main:
	$(DOCKER_COMPOSE) logs -f $(PROJECT_NAME)

logs-jupyter:
	$(DOCKER_COMPOSE) logs -f jupyter

logs-tensorboard:
	$(DOCKER_COMPOSE) logs -f tensorboard

# ==================== æ•°æ®å¤„ç† ====================

# åˆ›å»ºå¿…éœ€çš„ç›®å½•ç»“æ„
setup-dirs:
	@echo "ğŸ“ åˆ›å»ºé¡¹ç›®ç›®å½•..."
	mkdir -p $(DATA_ROOT) $(SIM_DATA_DIR) $(REAL_DATA_DIR) $(PROCESSED_DATA_DIR)
	mkdir -p $(CHECKPOINT_DIR) $(LOG_DIR) $(RESULT_DIR)
	mkdir -p $(PROCESSED_DATA_DIR)/train $(PROCESSED_DATA_DIR)/val $(PROCESSED_DATA_DIR)/test

# æ•°æ®é¢„å¤„ç†
preprocess: setup-dirs
	@echo "ğŸ”„ å¼€å§‹æ•°æ®é¢„å¤„ç†..."
	docker exec -it $(CONTAINER_NAME) python scripts/preprocess_data.py \
		--sim_dir $(SIM_DATA_DIR) \
		--real_dir $(REAL_DATA_DIR) \
		--output_dir $(PROCESSED_DATA_DIR) \
		--total_points 120000 \
		--global_points 30000

# æ£€æŸ¥æ•°æ®
check-data:
	@echo "ğŸ“Š æ£€æŸ¥æ•°æ®é›†çŠ¶æ€..."
	docker exec -it $(CONTAINER_NAME) python -c "\
	import os; \
	dirs = ['$(SIM_DATA_DIR)', '$(REAL_DATA_DIR)', '$(PROCESSED_DATA_DIR)']; \
	for d in dirs: \
		files = len([f for f in os.listdir(d) if f.endswith(('.npy', '.pt'))]) if os.path.exists(d) else 0; \
		print(f'{d}: {files} files')"

# ==================== æ¨¡å‹è®­ç»ƒ ====================

# å¼€å§‹è®­ç»ƒ
train:
	@echo "ğŸš€ å¼€å§‹æ¨¡å‹è®­ç»ƒ..."
	docker exec -it $(CONTAINER_NAME) python scripts/train.py \
		--experiment_name hierarchical_training

# æ¢å¤è®­ç»ƒ
train-resume:
	@echo "ğŸ”„ æ¢å¤è®­ç»ƒ..."
	docker exec -it $(CONTAINER_NAME) python scripts/train.py \
		--experiment_name hierarchical_training \
		--resume

# å¿«é€Ÿè®­ç»ƒï¼ˆç”¨äºæµ‹è¯•ï¼‰
train-debug:
	@echo "ğŸ› è°ƒè¯•æ¨¡å¼è®­ç»ƒ..."
	docker exec -it $(CONTAINER_NAME) python scripts/train.py \
		--experiment_name debug_training \
		--batch_size 2

# ç›‘æ§è®­ç»ƒè¿›åº¦
monitor:
	@echo "ğŸ‘ï¸ ç›‘æ§è®­ç»ƒè¿›åº¦..."
	@echo "ğŸ“ˆ TensorBoard: http://localhost:6006"
	@echo "ğŸ“Š æ£€æŸ¥æœ€æ–°æ—¥å¿—:"
	docker exec -it $(CONTAINER_NAME) tail -f logs/*/latest.log

# ==================== æµ‹è¯•ä¸æ¨ç† ====================

# è¿è¡Œæ¨¡å‹æµ‹è¯•
test:
	@echo "ğŸ§ª è¿è¡Œæ¨¡å‹æµ‹è¯•..."
	docker exec -it $(CONTAINER_NAME) python scripts/test.py \
		--checkpoint checkpoints/hierarchical_training/best_model.pth \
		--test_data $(PROCESSED_DATA_DIR) \
		--compute_all_metrics \
		--save_visualizations

# å•æ–‡ä»¶æ¨ç†ç¤ºä¾‹
inference:
	@echo "ğŸ”® è¿è¡Œæ¨ç†ç¤ºä¾‹..."
	docker exec -it $(CONTAINER_NAME) python scripts/inference.py \
		--checkpoint checkpoints/hierarchical_training/best_model.pth \
		--source $(SIM_DATA_DIR)/sample.npy \
		--reference $(REAL_DATA_DIR)/sample.npy \
		--output $(RESULT_DIR)/generated.npy \
		--visualize

# æ‰¹é‡æ¨ç†
inference-batch:
	@echo "ğŸ”® æ‰¹é‡æ¨ç†..."
	docker exec -it $(CONTAINER_NAME) python scripts/batch_inference.py \
		--checkpoint checkpoints/hierarchical_training/best_model.pth \
		--input_dir $(SIM_DATA_DIR) \
		--reference_dir $(REAL_DATA_DIR) \
		--output_dir $(RESULT_DIR)/batch

# å¯è§†åŒ–ç»“æœ
visualize:
	@echo "ğŸ¨ å¯è§†åŒ–ç»“æœ..."
	docker exec -it $(CONTAINER_NAME) python scripts/visualize_results.py \
		--original $(SIM_DATA_DIR)/sample.npy \
		--generated $(RESULT_DIR)/generated.npy \
		--reference $(REAL_DATA_DIR)/sample.npy \
		--interactive

# ==================== ç³»ç»Ÿå·¥å…· ====================

# æ£€æŸ¥GPUçŠ¶æ€
check-gpu:
	@echo "ğŸ–¥ï¸ æ£€æŸ¥GPUçŠ¶æ€..."
	docker exec -it $(CONTAINER_NAME) nvidia-smi
	@echo ""
	docker exec -it $(CONTAINER_NAME) python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'GPU count: {torch.cuda.device_count()}')"

# æ£€æŸ¥Pythonç¯å¢ƒ
check-env:
	@echo "ğŸ æ£€æŸ¥Pythonç¯å¢ƒ..."
	docker exec -it $(CONTAINER_NAME) python -c "\
	import torch, numpy, open3d, matplotlib; \
	print(f'PyTorch: {torch.__version__}'); \
	print(f'NumPy: {numpy.__version__}'); \
	print(f'Open3D: {open3d.__version__}'); \
	print(f'CUDA: {torch.version.cuda}'); \
	print(f'cuDNN: {torch.backends.cudnn.version()}')"

# æ€§èƒ½åŸºå‡†æµ‹è¯•
benchmark:
	@echo "âš¡ è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•..."
	docker exec -it $(CONTAINER_NAME) python scripts/benchmark.py

# ==================== æ¸…ç† ====================

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
clean:
	@echo "ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶..."
	find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
	find . -type f -name "*.pyc" -delete 2>/dev/null || true
	find . -type f -name "*.pyo" -delete 2>/dev/null || true
	find . -type f -name ".DS_Store" -delete 2>/dev/null || true
	find . -type f -name "*.log.*" -delete 2>/dev/null || true
	docker system prune -f

# æ·±åº¦æ¸…ç†ï¼ˆåŒ…æ‹¬Dockeré•œåƒå’Œæ•°æ®ï¼‰
clean-all: clean
	@echo "ğŸ—‘ï¸ æ·±åº¦æ¸…ç†..."
	$(DOCKER_COMPOSE) down -v --remove-orphans
	docker system prune -af --volumes
	@echo "âš ï¸ è­¦å‘Š: è¿™å°†åˆ é™¤æ‰€æœ‰æœªä½¿ç”¨çš„Dockerèµ„æº!"

# æ¸…ç†æ—¥å¿—æ–‡ä»¶
clean-logs:
	@echo "ğŸ“œ æ¸…ç†æ—¥å¿—æ–‡ä»¶..."
	find $(LOG_DIR) -name "*.log" -mtime +7 -delete 2>/dev/null || true

# æ¸…ç†ç»“æœæ–‡ä»¶
clean-results:
	@echo "ğŸ—‘ï¸ æ¸…ç†ç»“æœæ–‡ä»¶..."
	rm -rf $(RESULT_DIR)/*
	mkdir -p $(RESULT_DIR)

# ==================== å¼€å‘å·¥å…· ====================

# ä»£ç æ ¼å¼åŒ–
format:
	@echo "ğŸ¨ ä»£ç æ ¼å¼åŒ–..."
	docker exec -it $(CONTAINER_NAME) black .
	docker exec -it $(CONTAINER_NAME) isort .

# ä»£ç æ£€æŸ¥
lint:
	@echo "ğŸ” ä»£ç æ£€æŸ¥..."
	docker exec -it $(CONTAINER_NAME) flake8 .
	docker exec -it $(CONTAINER_NAME) mypy .

# è¿è¡Œæ‰€æœ‰æµ‹è¯•
test-all:
	@echo "ğŸ§ª è¿è¡Œæ‰€æœ‰æµ‹è¯•..."
	docker exec -it $(CONTAINER_NAME) pytest tests/ -v --cov=.

# ==================== å¿«æ·æ–¹å¼ ====================

# ä¸€é”®å¯åŠ¨å¼€å‘ç¯å¢ƒ
dev: up jupyter tensorboard
	@echo "ğŸ¯ å¼€å‘ç¯å¢ƒå·²å°±ç»ª!"

# å®Œæ•´çš„å·¥ä½œæµç¨‹
workflow: setup-dirs preprocess train test
	@echo "âœ… å®Œæ•´å·¥ä½œæµç¨‹æ‰§è¡Œå®Œæˆ!"