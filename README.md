# ç‚¹äº‘é£æ ¼è½¬æ¢é¡¹ç›® - å®Œæ•´æ–‡æ¡£

## é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®ä½¿ç”¨Diffusion Modelå®ç°å¤§è§„æ¨¡ç‚¹äº‘ï¼ˆ12ä¸‡ç‚¹ï¼‰çš„é£æ ¼è½¬æ¢ï¼Œå°†ä»¿çœŸç‚¹äº‘è½¬æ¢ä¸ºå…·æœ‰çœŸå®ä¸–ç•Œç‰¹å¾çš„ç‚¹äº‘ã€‚é¡¹ç›®ç‰¹ç‚¹ï¼š

- ğŸš€ åŸºäºDiffusion Modelçš„ç¨³å®šè®­ç»ƒ
- ğŸ”§ æ™ºèƒ½åˆ†å—å¤„ç†å¤§è§„æ¨¡ç‚¹äº‘
- ğŸ¯ é«˜è´¨é‡çš„å—èåˆç®—æ³•
- ğŸ“Š å®Œæ•´çš„è®­ç»ƒ/æµ‹è¯•/æ¨ç†æµç¨‹
- ğŸ³ Dockerå®¹å™¨åŒ–éƒ¨ç½²

## é¡¹ç›®ç»“æ„

```
pointcloud_style_transfer/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ config.py                  # é…ç½®ç®¡ç†
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ diffusion_model.py         # Diffusionæ¨¡å‹æ ¸å¿ƒ
â”‚   â”œâ”€â”€ pointnet2_encoder.py       # PointNet++ç‰¹å¾æå–
â”‚   â”œâ”€â”€ chunk_fusion.py            # å—èåˆæ¨¡å—
â”‚   â””â”€â”€ losses.py                  # æŸå¤±å‡½æ•°å®šä¹‰
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dataset.py                 # æ•°æ®é›†ç±»
â”‚   â”œâ”€â”€ preprocessing.py           # æ•°æ®é¢„å¤„ç†
â”‚   â””â”€â”€ augmentation.py            # æ•°æ®å¢å¼º
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ trainer.py                 # è®­ç»ƒå™¨
â”‚   â”œâ”€â”€ progressive_trainer.py     # æ¸è¿›å¼è®­ç»ƒ
â”‚   â””â”€â”€ validator.py               # éªŒè¯å™¨
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ metrics.py                 # è¯„ä¼°æŒ‡æ ‡
â”‚   â””â”€â”€ tester.py                  # æµ‹è¯•å™¨
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ visualization.py           # å¯è§†åŒ–å·¥å…·
â”‚   â”œâ”€â”€ logger.py                  # æ—¥å¿—ç®¡ç†
â”‚   â””â”€â”€ checkpoint.py              # æ£€æŸ¥ç‚¹ç®¡ç†
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ preprocess_data.py         # æ•°æ®é¢„å¤„ç†è„šæœ¬
â”‚   â”œâ”€â”€ train.py                   # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ test.py                    # æµ‹è¯•è„šæœ¬
â”‚   â”œâ”€â”€ inference.py               # æ¨ç†è„šæœ¬
â”‚   â””â”€â”€ visualize_results.py       # ç»“æœå¯è§†åŒ–è„šæœ¬
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile                 # Dockeré•œåƒå®šä¹‰
â”‚   â”œâ”€â”€ docker-compose.yml         # Docker Composeé…ç½®
â”‚   â””â”€â”€ requirements.txt           # Pythonä¾èµ–
â”œâ”€â”€ datasets/                      # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ simulation/               # ä»¿çœŸç‚¹äº‘
â”‚   â”œâ”€â”€ real_world/              # çœŸå®ç‚¹äº‘
â”‚   â””â”€â”€ processed/               # é¢„å¤„ç†åçš„æ•°æ®
â”œâ”€â”€ experiments/                   # å®éªŒç»“æœ
â”œâ”€â”€ checkpoints/                   # æ¨¡å‹æ£€æŸ¥ç‚¹
â”œâ”€â”€ logs/                         # è®­ç»ƒæ—¥å¿—
â””â”€â”€ README.md                     # é¡¹ç›®è¯´æ˜

```

## ç¯å¢ƒè¦æ±‚

- Ubuntu 24.04
- CUDA 12.5
- Python 3.10+
- PyTorch 2.1+
- è‡³å°‘16GB GPUå†…å­˜ï¼ˆæ¨è24GB+ï¼‰

## å¿«é€Ÿå¼€å§‹

### 1. ä½¿ç”¨Dockerï¼ˆæ¨èï¼‰

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/your-repo/pointcloud-style-transfer.git
cd pointcloud-style-transfer

# æ„å»ºå¹¶å¯åŠ¨Dockerå®¹å™¨
docker-compose up -d

# è¿›å…¥å®¹å™¨
docker exec -it pointcloud-style-transfer bash
```

### 2. æœ¬åœ°å®‰è£…

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n pc_style python=3.10
conda activate pc_style

# å®‰è£…PyTorch (CUDA 12.5)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# å®‰è£…å…¶ä»–ä¾èµ–
pip install -r requirements.txt
```

## è¯¦ç»†ä½¿ç”¨æŒ‡å—

### æ­¥éª¤1: æ•°æ®å‡†å¤‡

å°†æ‚¨çš„ç‚¹äº‘æ•°æ®ç»„ç»‡æˆä»¥ä¸‹ç»“æ„ï¼š
```
datasets/
â”œâ”€â”€ simulation/
â”‚   â”œâ”€â”€ sim_001.npy  # shape: (120000, 3)
â”‚   â”œâ”€â”€ sim_002.npy
â”‚   â””â”€â”€ ...
â””â”€â”€ real_world/
    â”œâ”€â”€ real_001.npy  # shape: (120000, 3)
    â”œâ”€â”€ real_002.npy
    â””â”€â”€ ...
```

### æ­¥éª¤2: æ•°æ®é¢„å¤„ç†

```bash
python scripts/preprocess_data.py \
    --sim_dir datasets/simulation \
    --real_dir datasets/real_world \
    --output_dir datasets/processed \
    --chunk_size 4096 \
    --overlap_ratio 0.2 \
    --use_lidar_mode
```

å‚æ•°è¯´æ˜ï¼š
- `--chunk_size`: æ¯ä¸ªå—çš„ç‚¹æ•°ï¼ˆé»˜è®¤2048ï¼‰
- `--overlap_ratio`: å—ä¹‹é—´çš„é‡å ç‡ï¼ˆé»˜è®¤0.3ï¼‰
- `--num_workers`: å¹¶è¡Œå¤„ç†çš„è¿›ç¨‹æ•°

### æ­¥éª¤3: è®­ç»ƒæ¨¡å‹

```bash
#supervised training
python scripts/train.py \
    --data_dir datasets/processed \
    --experiment_name my_experiment \
    --batch_size 8 \
    --num_epochs 40
#unsupervised training
python scripts/train_unsupervised.py
```

é«˜çº§è®­ç»ƒé€‰é¡¹ï¼š
```bash
python scripts/train.py \
    --data_dir datasets/processed \
    --experiment_name advanced_experiment \
    --batch_size 8 \
    --num_epochs 100 \
    --learning_rate 0.0001 \
    --progressive_training \
    --initial_chunks 10 \
    --chunks_increment 10 \
    --use_ema \
    --gradient_clip 1.0 \
    --resume checkpoints/latest.pth
```

### æ­¥éª¤4: æµ‹è¯•æ¨¡å‹

```bash
python scripts/test.py \
    --checkpoint experiments/my_experiment/checkpoints/best_model.pth \
    --test_data datasets/processed \
    --compute_all_metrics

#unsupervised testing
python scripts/test_unsupervised.py \
    --checkpoint experiments/test1/checkpoints/latest.pth \
    --test_data datasets/processed \
    --compute_all_metrics
```

### æ­¥éª¤5: æ¨ç†ï¼ˆè½¬æ¢æ–°çš„ç‚¹äº‘ï¼‰

å•ä¸ªæ–‡ä»¶ï¼š
```bash
#supervised inference
python scripts/inference.py \
    --checkpoint checkpoints/best_model.pth \
    --sim_input path/to/simulation.npy \
    --real_reference path/to/reference.npy \
    --output path/to/output.npy
#unsupervised inference
python scripts/inference_unsupervised.py \
    --checkpoint experiments/unsupervised_test/checkpoints/latest.pth \
    --sim_input path/to/simulation.npy \
    --real_reference path/to/reference.npy \
    --output path/to/output.npy
```

æ‰¹é‡å¤„ç†ï¼š
```bash
#supervised inference
python scripts/inference.py \
    --checkpoint checkpoints/best_model.pth \
    --sim_folder path/to/sim_folder \
    --real_reference path/to/real_reference.npy \
    --output_folder path/to/output_folder \
    --batch_process

#unsupervised inference
python scripts/inference_unsupervised.py \
    --checkpoint experiments/test1/checkpoints/latest.pth \
    --source datasets/test/000000.npy \
    --reference datasets/real_world/000000.npy \
    --output results/000000.npy
```

### æ­¥éª¤6: å¯è§†åŒ–ç»“æœ

```bash
python scripts/visualize_results.py \
    --original datasets/simulation/000000.npy \
    --generated results/000000.npy \
    --reference datasets/real_world/000000.npy \
    --output_path visualization.png
```

## é…ç½®å‚æ•°è¯¦è§£

### ä¸»è¦é…ç½® (config/config.py)

```python
# æ•°æ®å‚æ•°
total_points: 120000      # å®Œæ•´ç‚¹äº‘ç‚¹æ•°
chunk_size: 2048         # æ¯ä¸ªå—çš„ç‚¹æ•°
overlap_ratio: 0.3       # å—é‡å ç‡

# æ¨¡å‹å‚æ•°
model_type: "diffusion"  # æ¨¡å‹ç±»å‹
num_timesteps: 1000      # Diffusionæ­¥æ•°
beta_schedule: "cosine"  # å™ªå£°è°ƒåº¦

# è®­ç»ƒå‚æ•°
batch_size: 8            # æ‰¹å¤§å°
num_epochs: 100          # è®­ç»ƒè½®æ•°
learning_rate: 0.0001    # å­¦ä¹ ç‡

# æŸå¤±æƒé‡
lambda_reconstruction: 1.0  # é‡å»ºæŸå¤±
lambda_perceptual: 0.5     # æ„ŸçŸ¥æŸå¤±
lambda_continuity: 0.5     # è¿ç»­æ€§æŸå¤±
lambda_boundary: 1.0       # è¾¹ç•ŒæŸå¤±
```

## è®­ç»ƒæŠ€å·§

1. **å†…å­˜ä¼˜åŒ–**ï¼š
   - å‡å°`batch_size`å’Œ`chunk_size`
   - ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
   - å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ

2. **è®­ç»ƒç¨³å®šæ€§**ï¼š
   - ä½¿ç”¨EMAï¼ˆæŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼‰
   - æ¸è¿›å¼è®­ç»ƒï¼ˆä»å°‘é‡å—å¼€å§‹ï¼‰
   - åˆé€‚çš„å­¦ä¹ ç‡è°ƒåº¦

3. **è´¨é‡æå‡**ï¼š
   - å¢å¤§`overlap_ratio`æé«˜å—èåˆè´¨é‡
   - è°ƒæ•´æŸå¤±æƒé‡å¹³è¡¡å„é¡¹æŒ‡æ ‡
   - ä½¿ç”¨æ›´å¤šçš„è®­ç»ƒæ•°æ®

## å¸¸è§é—®é¢˜

### Q1: å†…å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

```bash
# å‡å°æ‰¹å¤§å°å’Œå—å¤§å°
python scripts/train.py \
    --batch_size 4 \
    --chunk_size 1024 \
    --gradient_accumulation_steps 4
```

### Q2: è®­ç»ƒæŸå¤±ä¸ä¸‹é™ï¼Ÿ

- æ£€æŸ¥æ•°æ®é¢„å¤„ç†æ˜¯å¦æ­£ç¡®
- å°è¯•è°ƒæ•´å­¦ä¹ ç‡
- ç¡®ä¿ä»¿çœŸå’ŒçœŸå®ç‚¹äº‘å¯¹åº”å…³ç³»æ­£ç¡®

### Q3: ç”Ÿæˆç»“æœæœ‰æ˜æ˜¾å—è¾¹ç•Œï¼Ÿ

- å¢å¤§`overlap_ratio`åˆ°0.4æˆ–0.5
- å¢åŠ `lambda_boundary`æƒé‡
- ä½¿ç”¨æ›´å¤šè®­ç»ƒè½®æ•°

## æ€§èƒ½åŸºå‡†

åœ¨NVIDIA A100 GPUä¸Šçš„æµ‹è¯•ç»“æœï¼š

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| è®­ç»ƒé€Ÿåº¦ | ~50 batch/min |
| æ¨ç†é€Ÿåº¦ | ~2 ç§’/ç‚¹äº‘ |
| GPUå†…å­˜ä½¿ç”¨ | ~12GB |
| æœ€ç»ˆChamferè·ç¦» | 0.0015 |

## æ‰©å±•åŠŸèƒ½

### 1. å¤šGPUè®­ç»ƒ

```bash
python -m torch.distributed.launch \
    --nproc_per_node=4 \
    scripts/train.py \
    --data_dir datasets/processed \
    --distributed
```

### 2. æ··åˆç²¾åº¦è®­ç»ƒ

```bash
python scripts/train.py \
    --data_dir datasets/processed \
    --use_amp \
    --amp_level O1
```

### 3. å®æ—¶ç›‘æ§

ä½¿ç”¨TensorBoardï¼š
```bash
tensorboard --logdir experiments/my_experiment/logs
```

## è®¸å¯è¯

MIT License

## å¼•ç”¨

å¦‚æœæ‚¨ä½¿ç”¨æœ¬é¡¹ç›®ï¼Œè¯·å¼•ç”¨ï¼š
```bibtex
@misc{pointcloud_style_transfer,
  title={Point Cloud Style Transfer with Diffusion Models},
  author={WANG XINYU},
  year={2024},
  publisher={GitHub},
  url={https://github.com/wangxy0820/pointcloud-style-transfer}
}
```
